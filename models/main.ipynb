{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://git.wur.nl/bioinformatics/fte40306-advanced-machine-learning-project-data data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TobXq7bPZ_CA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "transform = transforms.ToPILImage()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qH38KsDMOvu"
   },
   "outputs": [],
   "source": [
    "# Import two files: pretrain.embedding.edit and pretrain.labels.edit\n",
    "embedding_data = pd.read_csv(\"data/pretrain.embedding.edit\", header = None, index_col=False) \n",
    "\n",
    "# 1648 numerical descriptors per protein\n",
    "label_data = pd.read_csv(\"data/pretrain.labels.edit\", header = None, index_col=False)\n",
    "\n",
    "# Information on the proteins; first column contains identifier (can be ignored)\n",
    "GO_data = pd.read_csv(\"data/pretrain.go\", header = None, index_col=False)\n",
    "\n",
    "# First column: protein identifier, followed by 1/0 to indicate assignment of protein to three different functions:\n",
    "# membrane [GO:0016020], ATP binding [GO:0005524], DNA binding [GO:0003677]\n",
    "print(embedding_data.shape,label_data.shape,GO_data.shape)\n",
    "nfeatures = embedding_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YN6vNjA81dc"
   },
   "source": [
    "## Step 1. Visualize and analyze the contents of the provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4uhqVSGPWTl"
   },
   "outputs": [],
   "source": [
    "class ShapemerDataset(Dataset):\n",
    "  def __init__(self, data, transform=None):\n",
    "    self.data = data\n",
    "    self.transform = transform\n",
    "    self.X = self.data\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.X.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    Xi = self.X[idx]\n",
    "    if self.transform is not None:\n",
    "      Xi = self.transform(Xi)\n",
    "    return Xi\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_data, label_data, test_size=0.33, random_state=42)\n",
    "train_dataset=ShapemerDataset(torch.tensor(X_train.to_numpy()).to(torch.float32))\n",
    "test_dataset=ShapemerDataset(torch.tensor(X_test.to_numpy()).to(torch.float32))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_dataset  , batch_size=128, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MmrUHBk86pU"
   },
   "source": [
    "Add your code and analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC5i61At9z7i"
   },
   "source": [
    "## Step 2. Train autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4612Pjz0bTX"
   },
   "source": [
    "As an example, we use here a simple autoencoder with both the encoder and the decoder containing two linear layers. Make sure to vary on this design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3SnVZGOaRHS"
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "  \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=64\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=64, out_features=64\n",
    "        )\n",
    "        self.decoder_hidden_layer = nn.Linear(\n",
    "            in_features=64, out_features=64\n",
    "        )\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=64, out_features=kwargs[\"input_shape\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        activation = self.decoder_hidden_layer(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5cDT9CL1A4I"
   },
   "source": [
    "We now define an instance of the AE model, as well as the optimization approach and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arMISoW1b5Rd"
   },
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a model from `AE` autoencoder class and load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=nfeatures).to(device)\n",
    "\n",
    "# Create an optimizer object: Adam with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNHhMpNqBEzn"
   },
   "source": [
    "We can then train an autoencoder as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdhXOLQ9lv_E"
   },
   "outputs": [],
   "source": [
    "epochs=10 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss = 0\n",
    " \n",
    "    for batch_features in train_loader:\n",
    "        # Load it to the active device\n",
    "        batch_features = batch_features.view(-1, nfeatures).to(device)\n",
    " \n",
    "        # Reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # Compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # Compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # Compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # Display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98fXgup7_RVV"
   },
   "source": [
    "## Step 3. Visualization using t-SNE or UMAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQV0nLlZ_V5r"
   },
   "source": [
    "Add your code and analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08I_1UmHAQJ7"
   },
   "source": [
    "## Step 4. Supervised prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfNtOZVjAUo3"
   },
   "source": [
    "Add your code and analysis below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB7cTtPJAlsp"
   },
   "source": [
    "## Step 5. Kernel PCA (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kv-ywhQA_yJ"
   },
   "source": [
    "Add your code and analysis below."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
